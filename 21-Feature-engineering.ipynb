{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Making Sense of Data ...\n",
    "\n",
    "\n",
    "For this notebook you need to have the `scikit-learn` (http://scikit-learn.org/stable/index.html) module installed, which is part of a normal Anaconda installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Feature Spaces\n",
    "\n",
    "## One-dimensional Features Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "\n",
    "centers = [[60], [120], [170], [240]]\n",
    "data, _ = make_blobs(n_samples=400, n_features=1, cluster_std=4, centers=centers)\n",
    "\n",
    "data_1d = np.rint(data).astype(np.uint8)\n",
    "plt.xlim(0, 255)\n",
    "plt.ylim(-0.3, 0.3)\n",
    "\n",
    "y = np.zeros(np.shape(data))\n",
    "plt.plot(data_1d , y, 'b|', ms=50)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Two-dimensional Features Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "centers = [[2, 1], [0, 0], [1, -1]]\n",
    "data_2d, _ = make_blobs(n_samples=2500, centers=centers, \n",
    "                        cluster_std=0.37)\n",
    "\n",
    "plt.plot(data_2d[:,0], data_2d[:,1], 'b.')\n",
    "\n",
    "plt.title('Estimated number of clusters:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Three-dimensional Features Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "\n",
    "centers = [[2, 1, 0], [0, -1, -1], [1, -1, 3]]\n",
    "data_3d, _ = make_blobs(n_samples=2500, centers=centers, cluster_std=0.37)\n",
    "x, y, z = data_3d[:,0], data_3d[:,1], data_3d[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, linewidth=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feature vectors as descriptions of things\n",
    "\n",
    "Let's say we have a Person class:\n",
    "\n",
    "```python\n",
    "\n",
    "class Person:\n",
    "    \n",
    "    def __init__(self, age, height):\n",
    "        self.age = age\n",
    "        self.height = height\n",
    "```\n",
    "\n",
    "A Person is described by two **features**: `age` and `height`\n",
    "\n",
    "* So a **feature vector** for a person would have 2 dimensions\n",
    "  * $x^1 = $ age\n",
    "  * $x^2 = $ height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feature vectors in high dimensions\n",
    "\n",
    "* Imagine an image with the resolution `1024 x 800`\n",
    "  * How many pixels does that image have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* That image has `1024 * 800 = 819200` features!\n",
    "```python\n",
    "x[0]      # First feature\n",
    "x[819199] # Last feature\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Motivating the problem\n",
    "\n",
    "“We need to be able to predict whether a particular\n",
    "customer will stay with us. Here are the logs of customers’ interactions with our product for\n",
    "five years.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What information can we get from a log?\n",
    "\n",
    "* Timestamp\n",
    "* Number of connections\n",
    "* Frequency of connections\n",
    "* Session duration\n",
    "* ...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The more precisely we can describe the data, the better our model gets!\n",
    "\n",
    "We want to select the information that is important and *remove* the ones that aren't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature engineering\n",
    "\n",
    "The problem of transforming raw data into a dataset is called feature engineering.\n",
    "\n",
    "Goal: describe data with *informative* features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Today: techniques to encode data in specific ways\n",
    "\n",
    "* One-hot\n",
    "* Binning\n",
    "* Word embeddings\n",
    "* Normalisation\n",
    "* Standardisation\n",
    "* Dealing with missing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## One-hot encoding\n",
    "\n",
    "Imagine $n$ features. One-hot encoding means setting **one** feature to 1 and the rest to 0.\n",
    "\n",
    "Example:\n",
    " * Features `[Left, Right]`: `[1, 0]`\n",
    " * Features `[M, T, W, T, F, S, S]`: `[0, 0, 1, 0, 0, 0]`\n",
    " * Features `[M, F, X]`: `[0, 1, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "xs = [['Male'], ['Female'], ['Female']]\n",
    "encoder.fit_transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "encoder.fit_transform(xs).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "xs = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "encoder.fit_transform(xs).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Word embeddings\n",
    "\n",
    "How do we represent words?\n",
    "\n",
    "Can we make them into feature vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Yes, yes we can!\n",
    "\n",
    "![](images/word-embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(corpus).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "* Use the `CountVectorizer` from `sklearn.feature_extraction` to read the book `data/moby_dick.txt`\n",
    "  * How many times does the word 'wood' appear?\n",
    "* Use the `load_digits` function from the `sklearn.datasets` package to load a `sklearn` dataset\n",
    "  * The package contains `.data` of 8x8 images. Extract the first image in an 8x8 array\n",
    "  * Use the `plt.imshow` function to plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How do we find clusters?\n",
    "\n",
    "Humans are quite good in quickly finding clusters when looking at the data visualizations above. The problem is, how to make a machine find clusters.\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html#sphx-glr-auto-examples-cluster-plot-mean-shift-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "def mean_shift(data, n_samples=1000):\n",
    "    bandwidth = estimate_bandwidth(data, quantile=0.2, \n",
    "                                   n_samples=n_samples)\n",
    "\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(data)\n",
    "    labels = ms.labels_\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    labels_unique = np.unique(labels)\n",
    "    n_clusters = len(labels_unique)\n",
    "\n",
    "    print('Number of estimated clusters : {}'.format(n_clusters))\n",
    "    \n",
    "    return labels, cluster_centers, n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from itertools import cycle\n",
    "\n",
    "labels, cluster_centers, n_clusters = mean_shift(data_1d)\n",
    "\n",
    "plt.cla()\n",
    "plt.xlim(0, 255)\n",
    "plt.ylim(-0.3, 0.3)\n",
    "\n",
    "colors = cycle('bgrcmy')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = (labels == k)\n",
    "    cluster_center = cluster_centers[k]\n",
    "    \n",
    "    x = data_1d[my_members, 0]\n",
    "    y = np.zeros(np.shape(x))\n",
    "\n",
    "    plt.plot(x , y, col + '|', ms=50)\n",
    "    plt.plot(cluster_center[0] , 0, 'k|', ms=70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "labels, cluster_centers, n_clusters = mean_shift(data_2d)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colors = cycle('bgrcmy')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = (labels == k)\n",
    "    cluster_center = cluster_centers[k]\n",
    "    \n",
    "    x, y = data_2d[my_members,0], data_2d[my_members,1]\n",
    "    ax.scatter(x, y, c=col, linewidth=0.2)\n",
    "    ax.scatter(cluster_center[0], cluster_center[1], c='k', s=50, linewidth=0.2)\n",
    "    \n",
    "plt.title('Estimated number of clusters: {}'.format(n_clusters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "labels, cluster_centers, n_clusters = mean_shift(data_3d)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = cycle('bgrcmy')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = (labels == k)\n",
    "    cluster_center = cluster_centers[k]\n",
    "    \n",
    "    x, y, z = data_3d[my_members,0], data_3d[my_members,1], data_3d[my_members,2]\n",
    "    ax.scatter(x, y, z, c=col,  linewidth=0.2, alpha=0.1)\n",
    "    ax.scatter(cluster_center[0], cluster_center[1], cluster_center[2], s=150, c='k')\n",
    "    \n",
    "plt.title('Estimated number of clusters: {}'.format(n_clusters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "filename = './iris_data.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.unique(df['Species'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colors = cycle('bgrcmy')\n",
    "for label, col in zip(labels, colors):\n",
    "    print(label, col)\n",
    "    x = df[df['Species'] == label]['Sepal length']\n",
    "    y = df[df['Species'] == label]['Sepal width']\n",
    "\n",
    "    ax.scatter(x, y, c=col,  linewidth=0.2)\n",
    "    \n",
    "plt.title('Sepal length vs. width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_2d = df[['Sepal length', 'Sepal width']].as_matrix()\n",
    "labels, cluster_centers, n_clusters = mean_shift(data_2d)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colors = cycle('bgrcmy')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = (labels == k)\n",
    "    cluster_center = cluster_centers[k]\n",
    "    \n",
    "    x, y = data_2d[my_members,0], data_2d[my_members,1]\n",
    "    ax.scatter(x, y, c=col,  linewidth=0.2)\n",
    "    ax.scatter(cluster_center[0], cluster_center[1], c='k', s=50, linewidth=0.2)\n",
    "    \n",
    "plt.title('Estimated number of clusters: {}'.format(n_clusters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How does this work?\n",
    "\n",
    "  * http://stackoverflow.com/a/17912660\n",
    "  * http://www.chioka.in/meanshift-algorithm-for-the-rest-of-us-python/\n",
    "  * https://en.wikipedia.org/wiki/Mean_shift\n",
    "  * https://github.com/mattnedrich/MeanShift_py\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/mattnedrich/MeanShift_py.git\n",
    "```\n",
    "\n",
    "The following is the entry from Stackoverflow http://stackoverflow.com/a/17912660 explaining the mean shift algorithm. It is copied here for convinience and readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### The image data is converted into feature space\n",
    "![](https://i.stack.imgur.com/80Uaa.jpg)\n",
    "In case of a gray-scale image, all you have are intensity values, so feature space will only be one-dimensional. (You might compute some texture features, for instance, and then your feature space would be two dimensional – and you would be segmenting based on intensity and texture)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Search windows are distributed over the feature space \n",
    "![](https://i.stack.imgur.com/52HFX.jpg)\n",
    "The number of windows, window size, and initial locations are arbitrary for this example – something that can be fine-tuned depending on specific applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Mean-Shift iterations:\n",
    "\n",
    "### 1.) The MEANs of the data samples within each window are computed \n",
    "![](https://i.stack.imgur.com/JaOo5.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "### 2.) The windows are SHIFTed to the locations equal to their previously computed means \n",
    "![](https://i.stack.imgur.com/7Nk75.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Steps 1.) and 2.) are repeated until convergence, i.e. all windows have settled on final locations \n",
    "![](https://i.stack.imgur.com/5127k.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### The windows that end up on the same locations are merged \n",
    "![](https://i.stack.imgur.com/SryA8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### The data is clustered according to the window traversals \n",
    "![](https://i.stack.imgur.com/A871k.jpg)\n",
    "\n",
    "That is, all data that was traversed by windows that ended up at, say, location \"2\", will form a cluster associated with that location.\n",
    "\n",
    "So, this segmentation will (coincidentally) produce three groups. Choosing different window sizes and initial locations might produce different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What else can I use this for?\n",
    "\n",
    "For example for image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import cv2\n",
    "import webget\n",
    "\n",
    "# url = 'https://github.com/opencv/opencv/raw/master/samples/data/rubberwhale2.png'\n",
    "url = 'https://github.com/opencv/opencv/raw/master/samples/data/baboon.jpg'\n",
    "# url = 'https://github.com/mattnedrich/MeanShift_py/raw/master/sample_images/mean_shift_image.jpg'\n",
    "webget.download(url)\n",
    "\n",
    "img = cv2.imread(os.path.basename(url))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "plt.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lab_image = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "img = cv2.medianBlur(lab_image, 5)\n",
    "    \n",
    "img_lst = img.reshape((img.shape[0] * img.shape[1], 3))\n",
    "img_lst_orig = np.copy(img_lst)\n",
    "\n",
    "labels, cluster_centers, n_clusters = mean_shift(img_lst)\n",
    "\n",
    "label_img = labels.reshape(height, width)\n",
    "for l in range(n_clusters):\n",
    "    img[label_img == l] = cluster_centers[l]\n",
    "\n",
    "rgb_segments = cv2.cvtColor(img, cv2.COLOR_Lab2RGB)\n",
    "plt.imshow(rgb_segments, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "labels, cluster_centers, n_clusters = mean_shift(img_lst_orig)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = cycle('cmybgr')\n",
    "for k, col in zip(range(n_clusters), colors):\n",
    "    my_members = (labels == k)\n",
    "    cluster_center = cluster_centers[k]\n",
    "    \n",
    "    x, y, z = img_lst_orig[my_members,0], img_lst_orig[my_members,1], img_lst_orig[my_members,2]\n",
    "    ax.scatter(x, y, z, c=col,  linewidth=0.2, alpha=0.1)\n",
    "    ax.scatter(cluster_center[0], cluster_center[1], cluster_center[2], s=150, c='k')\n",
    "    \n",
    "plt.title('Estimated number of clusters: {}'.format(n_clusters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(cluster_centers)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
